{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9146200,"sourceType":"datasetVersion","datasetId":5524489}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport torch\nimport torchvision.transforms as T\nfrom PIL import Image\nimport shap\nimport pandas as pd\nimport openai\nfrom IPython.display import display","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"openai.api_base = os.getenv('OPENROUTER_API_BASE', 'https://openrouter.ai/api/v1')\nopenai.api_key  = os.getenv('OPENROUTER_API_KEY')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_frames(video_path: str, interval: int = 30):\n    \"\"\"Yield (frame_index, PIL.Image) at every `interval` frames.\"\"\"\n    cap = cv2.VideoCapture(video_path)\n    idx = 0\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        if idx % interval == 0:\n            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            yield idx, Image.fromarray(img)\n        idx += 1\n    cap.release()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model and explainer once\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = torch.hub.load('pytorch/vision', 'vit_b_16', pretrained=True).to(device)\nmodel.eval()\n\npreprocess = T.Compose([\n    T.Resize((224, 224)),\n    T.ToTensor(),\n    T.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n])\nbackground = torch.zeros((1, 3, 224, 224), device=device)\nexplainer = shap.GradientExplainer(model, background)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_shap_for_video(video_path: str, interval: int = 30):\n    indices, shap_vals = [], []\n    for idx, frame in extract_frames(video_path, interval):\n        inp = preprocess(frame).unsqueeze(0).to(device)\n        shap_val = explainer.shap_values(inp)\n        indices.append(idx)\n        shap_vals.append(np.array(shap_val))\n    return np.array(indices), np.stack(shap_vals)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video_file = 'path/to/video.mp4'\nindices, shap_vals = compute_shap_for_video(video_file, interval=30)\nprint('Extracted frames:', indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def summarize_shap(shap_vals: np.ndarray, top_k: int = 3) -> str:\n    \"\"\"Return a brief summary of the most influential frames.\"\"\"\n    stats = np.mean(np.abs(shap_vals), axis=(1,2,3))\n    top_idxs = np.argsort(stats)[-top_k:][::-1]\n    means = stats[top_idxs].round(3).tolist()\n    return f\"Top frames: {top_idxs.tolist()}, mean abs SHAP: {means}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_description(shap_summary: str, tag: str) -> str:\n    prompt = (\n        f\"Video classified as {tag}. SHAP summary: {shap_summary}. \"\n        \"Explain in 2-3 sentences why the model considers it real or fake.\"\n    )\n    resp = openai.ChatCompletion.create(\n        model='deepseek-v3',\n        messages=[{'role':'user','content':prompt}],\n        temperature=0.7,\n        max_tokens=150\n    )\n    return resp.choices[0].message.content.strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary = summarize_shap(shap_vals)\ndescription = generate_description(summary, 'fake')\nprint(description)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CSV mapping: columns ['video_filename','tag']\ntag_df = pd.read_csv('video_tags.csv')\nresults = []\n\nfor _, row in tag_df.iterrows():\n    path, tag = row['video_filename'], row['tag']\n    idxs, vals = compute_shap_for_video(path)\n    summ = summarize_shap(vals)\n    desc = generate_description(summ, tag)\n    results.append({'video_path': path, 'tag': tag, 'description': desc})\n\ndf = pd.DataFrame(results)\n\ndisplay(df)                # show in notebook\ndf.to_excel('results.xlsx', index=False)  \nprint('Saved results.xlsx')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}